{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"AWS Amplify는 모바일 및 프런트엔드 개발자가 AWS에서 안전하고 확장 가능한 풀스택 애플리케이션을 구축하고 배포할 수 있도록 지원하는 제품입니다. 회사에서 서비스하고 있는 프로젝트에서 S3로 로그 파일을 주기적으로 업로드하는 기능을 구현하고 꾸준히 모니터링하였는데, 여러 Android 기기에서 java.lang.OutOfMemoryError 오류…","fields":{"slug":"/aws-amplify/"},"frontmatter":{"date":"February 25, 2025","title":"AWS Amplify Android 오픈소스 기여하기","tags":["opensource"]},"rawMarkdownBody":"\nAWS Amplify는 모바일 및 프런트엔드 개발자가 AWS에서 안전하고 확장 가능한 풀스택 애플리케이션을 구축하고 배포할 수 있도록 지원하는 제품입니다. 회사에서 서비스하고 있는 프로젝트에서 S3로 로그 파일을 주기적으로 업로드하는 기능을 구현하고 꾸준히 모니터링하였는데, 여러 Android 기기에서 [java.lang.OutOfMemoryError](https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/memleaks002.html) 오류가 반복적으로 발생하는 것을 발견했습니다.\n\n### 원인을 분석해보자\n수집된 크래시 리포트를 요약하면 다음과 같았습니다.\n```text\nFatal Exception: java.lang.OutOfMemoryError: Failed to allocate a 8388620 byte allocation with 8388608 free bytes and 19MB until OOM\n       at java.util.IdentityHashMap.resize(IdentityHashMap.java:476)\n       at java.util.IdentityHashMap.put(IdentityHashMap.java:452)\n       ...\n       at com.amplifyframework.storage.s3.transfer.TransferWorkerObserver$attachObserver$2.invokeSuspend(TransferWorkerObserver.kt:199)\n```\n\n[TransferWorkerObserver](https://github.com/aws-amplify/amplify-android/blob/main/aws-storage-s3/src/main/java/com/amplifyframework/storage/s3/transfer/TransferWorkerObserver.kt) 클래스에서 동일한 전송 태그에 대해 `LiveData.observeForever()`가 중복 호출되며, 여러 관찰자가 등록된 것으로 보였고, 이는 `LiveData` 내부의 [IdentityHashMap](https://docs.oracle.com/javase/8/docs/api/java/util/IdentityHashMap.html)이 과도하게 커져 메모리 할당에 실패하게 만들고, 특히 `Room` 라이브러리의 [InvalidationTracker](https://developer.android.com/reference/androidx/room/InvalidationTracker)와 연계된 `LiveData` 사용으로 메모리 사용량이 더 증가한 것으로 판단하였습니다.\n\n### 이슈 등록하기\n저는 먼저 이 문제를 공유하기 위해 템플릿에 맞추어 [이슈](https://github.com/aws-amplify/amplify-android/issues/2840)를 등록해주었습니다.\n\n다만, **보안상** 회사 코드를 전부 스니펫에 첨부할 수는 없었기 때문에 민감한 코드는 전부 제거하고 핵심 로직만 다시 재작성하였습니다. 이슈란에 첨부한 코드 스니펫은 다음과 같았습니다.\n\n```kotlin\n@HiltWorker\nclass LogUploadWorker @AssistedInject constructor(\n    @Assisted private val appContext: Context,\n    @Assisted workerParams: WorkerParameters,\n    @Dispatcher(IO) private val ioDispatcher: CoroutineDispatcher\n) : CoroutineWorker(appContext, workerParams) {\n\n    override suspend fun getForegroundInfo(): ForegroundInfo =\n        appContext.logSyncForegroundInfo()\n\n    override suspend fun doWork(): Result = withContext(ioDispatcher) {\n        try {\n            val externalFilesDirPath = inputData.getString(\"externalFilesDirPath\")\n            val externalFilesDir = externalFilesDirPath?.let { File(it) }\n            if (externalFilesDir != null && externalFilesDir.exists()) {\n                uploadLogFiles(externalFilesDir)\n            }\n        } catch (e: Exception) {\n            Timber.e(\"Log upload exception: ${e.message}\")\n            Result.retry()\n        }\n        Result.success()\n    }\n\n    @OptIn(ExperimentalCoroutinesApi::class, FlowPreview::class)\n    private suspend fun uploadLogFiles(externalFilesDir: File) {\n        val curFiles = externalFilesDir.listFiles()?.filter { file ->\n            System.currentTimeMillis() - file.lastModified() < TWO_WEEK_TIME_MILLIS\n        }?.sortedByDescending { it.lastModified() }\n\n        if (curFiles.isNullOrEmpty()) {\n            Timber.i(\"No log files or directory found.\")\n            return\n        }\n        \n        val environmentPrefix = if (BuildConfig.DEBUG) \"debug\" else \"release\"\n        val dateFormat = SimpleDateFormat(\"yyyy-MM-dd\", Locale.getDefault())\n\n        curFiles.forEach { file ->\n            val date = dateFormat.format(Date(file.lastModified()))\n            val fileIndex = file.name.substringBefore(\"_logs.txt\").takeLastWhile { it.isDigit() }\n            val key = \"$environmentPrefix/sample/$date/log$fileIndex.txt\"\n\n            try {\n                val result = Amplify.Storage.uploadFile(\n                    StoragePath.fromString(\"public/$key\"),\n                    file\n                ).result()\n                Timber.i(\"Log file upload successful: ${result.path}\")\n            } catch (error: Exception) {\n                Timber.e(\"Log file upload failed: ${error.message} - ${error.cause}\")\n            }\n        }\n    }\n\n    companion object {\n        private const val TWO_WEEK_TIME_MILLIS = 14 * 24 * 60 * 60 * 1000L\n\n        fun startUpUploadWork(\n            externalFilesDirPath: File?\n        ) = PeriodicWorkRequestBuilder<LogUploadWorker>(\n            1, TimeUnit.HOURS,\n            5, TimeUnit.MINUTES\n        )\n            .setConstraints(LogSyncConstraints)\n            .setBackoffCriteria(\n                BackoffPolicy.LINEAR,\n                MIN_BACKOFF_MILLIS,\n                TimeUnit.MILLISECONDS\n            )\n            .setInputData(\n                Data.Builder()\n                    .putString(\"externalFilesDirPath\", externalFilesDirPath?.absolutePath)\n                    .build()\n            )\n            .build()\n    }\n}\n```\n\n간단하게 위 스니펫의 로직을 설명하면, 먼저 로그 파일 디렉터리 경로를 기반으로 파일 객체를 생성하고, **2주** 이내에 수정된 파일들을 필터링하며, 최근 수정된 순서로 정렬한 뒤, 예외가 발생했을 때에는 `선형 재시도` 정책을 따르도록 설정해주었고, 각 파일에 대해 `빌드타입`에 따른 정보와, 파일의 수정 날짜, 파일 이름의 인덱스를 조합하여 AWS S3에 저장할 키를 구성하고, 이후 파일을 업로드하고 그 결과를 Timber 로그로 남기는 흐름입니다. 이 작업은 `주기적으로 실행되는 작업`에 해당하므로 [Workmanager](https://developer.android.com/topic/libraries/architecture/workmanager?hl=ko)의 [PeriodicWorkRequest.Builder](https://developer.android.com/reference/androidx/work/PeriodicWorkRequest.Builder)를 활용하였습니다.\n\n![](aws-amplify-issue-comment.png)\n\n이후 해당 이슈란의 코멘트를 통해 메인테이너분들과 이슈의 발생 빈도와 문제 발생 기기의 스펙 정보들을 요청받았고, 당시에는 [aws-amplify/amplify-android](https://github.com/aws-amplify/amplify-android) 라이브러리 자체의 문제라기보다는 `내가 구현한 코드에 문제가 있었나?`, `OOM이 발생하지 않도록 더 최적화 할수는 없는가?`라고 고민을 하였고, 이를 해결하기 위해 아래의 개선작업들을 진행했습니다.\n\n- 로그 파일 리스트를 즉시 모두 메모리에 로드하지 않고, 필요한 시점에만 File 객체를 생성하도록 개선하기\n- 14일 이상된 오래된 로그 파일들을 주기적으로 삭제하여 처리해야할 로그 파일 수 자체를 줄이기\n\n하지만, 이러한 노력에도 불구하고 여전히 주기적으로 OOM 오류들이 수집되었습니다.\n\n### 직접 수정해보자\n오픈소스와 관련된 활동을 한다면, 라이선스 규정을 잘 준수해야 합니다. 또한 오픈소스 프로젝트에 컨트리뷰션을 하기 전에는 `CONTRIBUTING.md` 파일을 꼼꼼하게 읽어 가이드라인을 잘 준수할 수 있도록 해야합니다.\n\n저는 직접 수정해보기로 마음먹었습니다. 수집된 크래시 리포트를 다시 분석하여 코드를 수정한 뒤 PR을 생성하였고, 수정된 코드는 아래와 같습니다.\n\n```kotlin\nimport java.util.concurrent.ConcurrentHashMap\n\nprivate val observedTags = ConcurrentHashMap.newKeySet<String>()\n\nprivate suspend fun attachObserver(tag: String) {\n    withContext(Dispatchers.Main) {\n        if (!observedTags.add(tag)) return@withContext\n        val liveData = workManager.getWorkInfosByTagLiveData(tag)\n        liveData.observeForever(this@TransferWorkerObserver)\n    }\n}\n\nprivate suspend fun removeObserver(tag: String) {\n    withContext(Dispatchers.Main) {\n        if (!observedTags.remove(tag)) return@withContext\n        workManager.getWorkInfosByTagLiveData(tag)\n            .removeObserver(this@TransferWorkerObserver)\n    }\n}\n```\n\nAWS Amplify Storage 모듈의 [TransferWorkerObserver](https://github.com/aws-amplify/amplify-android/blob/main/aws-storage-s3/src/main/java/com/amplifyframework/storage/s3/transfer/TransferWorkerObserver.kt) 클래스에 중복 관찰자 등록을 방지하는 로직을 추가하였고, [ConcurrentHashMap](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentHashMap.html)은 `thread-safe`하며, `ConcurrentHashMap.newKeySet()`은 `Set` 인터페이스를 제공해주는데, 태그가 이미 존재하면 `add()`는 `false`를 반환하고, 얼리 리턴을 통해 함수를 종료합니다. 마찬가지로 `remove()`는 태그가 `observedTags`에 없으면 false를 반환하고 함수를 종료시킵니다. 이를 통해 불필요한 중복된 태그 등록을 방지할 수 있도록 수정하였습니다.\n\n### 뿌듯한 결과\n![](aws-amplify-approve-comment.png)\n\n메인테이너분으로부터 좋은 아이디어라는 의견과 함께 몇 가지 제안사항들을 수정한 뒤에 최종 승인이 되었고, [2.27.1](https://github.com/aws-amplify/amplify-android/releases/tag/release_v2.27.1) 버전에 해당 작업이 반영되어 릴리즈 되었습니다 🎉 \n\n이러한 경험을 통해서 회사 프로젝트에서 사용중인 오픈소스 라이브러리 오류를 발견하면 적극적으로 PR을 올려 기여하고 문제를 수정하는 것이 중요하다고 느꼈고, 자주 사용했지만 몰랐던 라이브러리의 내부 동작을 살펴보는 경험을 하게 되었습니다.\n\n### 아쉬웠던 점, 그리고 반성\n\n> 만약 Heap Dump를 더욱 끈질기게 분석했더라면, 문제의 근본 원인을 더 빠르게 파악하고 보다 더 근거있는 이슈 트래킹에 큰 도움이 되었지 않았을까?"},{"excerpt":"안드로이드 개발자라면 Dalvik, ART에 대해서 많이 들어봤을 것입니다. Dalvik은 초기 안드로이드에서 사용된 가상 머신으로, 메모리와 배터리 제약을 극복하기 위해 스택 기반 대신 레지스터 기반 바이트코드를 사용하여 효율적으로 동작하도록 설계되었습니다. 이후 Android 5.0부터는 가 기본 런타임 환경으로 전환되었는데, ART는 설치 시 를 통…","fields":{"slug":"/jvm-under-the-hood/"},"frontmatter":{"date":"August 21, 2024","title":"책 『JVM 밑바닥까지 파헤치기』 후기","tags":["book"]},"rawMarkdownBody":"\n안드로이드 개발자라면 **Dalvik, ART**에 대해서 많이 들어봤을 것입니다. [Dalvik](https://en.wikipedia.org/wiki/Dalvik_(software))은 초기 안드로이드에서 사용된 가상 머신으로, 메모리와 배터리 제약을 극복하기 위해 스택 기반 대신 레지스터 기반 바이트코드를 사용하여 효율적으로 동작하도록 설계되었습니다. 이후 Android 5.0부터는 `ART(Android Runtime)`가 기본 런타임 환경으로 전환되었는데, ART는 설치 시 `AOT(Ahead-Of-Time)`를 통해 앱을 네이티브 코드로 변환하고, 필요에 따라 `JIT(Just-In-Time)`를 추가로 적용하여 실행 성능을 크게 향상시킵니다.\n\n마침 회사 백엔드 개발자분들께서도 JVM에 관심이 생겨 사내에서 함께 공부해 보자는 제안을 해주셨고, 평소 더 파보고 싶었던 JVM의 `GC`, `메모리 관리 기법` 등의 개념을 공부하면 Android 런타임 환경의 내부 동작 방식을 이해하는 데에 도움이 될 수 있을 것이라고 생각하여 설레는 마음으로 스터디에 합류하게 되었습니다.\n\n![책이 생각보다 훨씬 두꺼워서 놀랐었다...](jvm-under-the-hood.png)\n\n스터디 교재로는 [『JVM 밑바닥까지 파헤치기』](https://www.yes24.com/Product/Goods/126114513)라는 책을 선택했습니다. 책의 분량이 많았기 때문에 챕터별로 담당자를 지정해서 읽어오고, 이를 사내 컨플루언스에 문서화하고 발표하는 방식의 스터디를 진행하였습니다. 발표를 하면서도 짧은 질문과 의견들이 오고갔고, 주로 `이 부분에서 자신이 이해한 것이 맞는지?`를 중심으로 근거를 찾아가면서 스터디를 진행하였습니다.\n\n> 여러 챕터에 걸쳐서 안드로이드 개발자에게 좋은 내용들이 많았지만, 개인적으로는 가비지 컬렉터의 내용이 가장 좋았기 때문에 '3장 가비지 컬렉터와 메모리 할당 전략'의 핵심 내용들을 요약해서 정리해보도록 하겠습니다.\n\n### 가비지 컬렉션?\n가비지 컬렉션(GC)은 자바 언어에서 처음 소개한 기술이 아니며, MIT에서 개발된 리스프라는 언어가 시초라고 합니다. 이러한 가비지 컬렉션과 메모리 할당의 내부 동작을 이해하면 다양한 메모리 오버플로우, 메모리 누수 문제를 해결해야하는 상황에 도움이 될 수 있습니다. \n\n### 자바 힙과 메서드 영역은 불확실\n구현한 클래스마다 요구하는 메모리 크기가 다를 수 있습니다. 프로그램이 어떤 객체를 생성할지, 얼마나 많이 만들지는 오직 런타임에만 알 수 있습니다. 그래서 이 메모리 영역들의 회수는 동적으로 이루어지고, 가비지 컬렉터는 이런 영역을 관리하는 데 집중합니다.\n\n가비지 컬렉터가 **힙을 청소**하려면 어떤 객체가 살아 있고 죽었는지를 판단해야 하는데, 여기서 죽었다는 말은 어떤 식으로도 프로그램 코드에서 사용될 수 없다는 뜻입니다.\n\n여기서 객체가 살아있는지 판단하는 알고리즘으로 크게 두 가지로 나눌 수 있습니다.\n\n- 참조 카운팅 알고리즘\n- 도달 가능성 분석 알고리즘\n\n### 참조 카운팅 알고리즘\n1. 객체를 가리키는 참조 카운터를 추가. 참조하는 곳이 하나 늘어날 때마다 카운터 값을 1씩 증가\n2. 참조하는 곳이 하나 사라질 때마다 카운터 값을 1씩 감소\n3. 카운터 값이 0이 된 객체는 더는 사용될 수 없음\n\n> 마이크로소프트 COM, 파이썬, 러스트 등이 메모리 관리에 참조 카운팅 알고리즘 사용한다고 합니다.\n\n그런데 자바, 적어도 자바 가상 머신에서는 참조 카운팅을 사용하지 않는데, 그 이유는 바로 `순환 참조 문제`를 풀기 어렵기 때문입니다.\n\n```java\npublic class ReferenceCountingGC {\n  public Object instance = null;\n  // ...\n  public static void testGC() {\n    // 두 객체 생성\n    ReferenceCountingGC objA = new ReferenceCountingGC();\n    ReferenceCountingGC objB = new ReferenceCountingGC();\n    // 내부 필드로 서로를 참조\n    objA.instance = objB;\n    objB.instance = objA;\n    // 참조 해제\n    objA = null;\n    objB = null;\n    // 이 라인에서 GC가 수행된다면 objA와 objB가 회수될까?\n    System.gc();\n  }\n  public static void main(String[] args) {\n    testGC();\n  }\n}\n```\n\n참조를 해제한 시점부터 두 객체에 접근할 길이 사라지지만, 아직도 서로를 참조하고 있기 때문에 참조 카운터는 아직 0이 아닙니다. 따라서 참조 카운팅 알고리즘으로는 둘을 회수하지 못하게 됩니다.\n\n그러나 실행 결과 자바 가상머신에서 `objA`와 `objB`가 메모리에서 회수되었음을 확인할 수 있고, 이는 자바 가상 머신은 객체 생사 판단에 `참조 카운팅 알고리즘`을 사용하지 않는다는 것을 알 수 있습니다.\n\n### 도달 가능성 분석 알고리즘\n자바, C# 등의 주류 언어들은 객체 생사 판단에 도달 가능성 분석(reachability analysis) 알고리즘을 사용합니다. 이 알고리즘의 핵심은 `GC 루트` 입니다. 이 루트 객체들을 시작 노드 집합으로 사용하며, 시작 노드들에서 출발하여 참조하는 다른 객체들로 탐색하여 들어가는 흐름으로 진행됩니다. 이때 탐색 과정에서 만들어지는 경로를 `참조 체인(reference chain)`이라고 부릅니다.\n\n![](gc-root.png)\n\n단, 자바에서 GC 루트로 이용할 수 있는 객체는 정해져 있는데, 그 종류는 다음과 같습니다.\n\n- `가상 머신 스택(스택 프레임의 지역 변수 테이블)에서 참조하는 객체` : 현재 실행 중인 메서드에서 쓰는 매개 변수, 지역 변수, 임시 변수 등\n- `메서드 영역에서 클래스가 정적 필드로 참조하는 객체` : 자바 클래스의 참조 타입 정적 변수\n- `메서드 영역에서 상수로 참조되는 객체` : 문자열 테이블 안의 참조\n- `네이티브 메서드 스택에서 JNI가 참조하는 객체`\n- `자바 가상 머신 내부에서 쓰이는 참조` : 기본 데이터 타입에 해당하는 Class 객체, 시스템 클래스 로더 등\n- `동기화 락(synchronized 키워드)으로 잠겨 있는 모든 객체`\n- `자바 가상 머신 내부 상황을 반영하는 JMXBean` : JVMTI에 등록된 콜백, 로컬 코드 캐시 등\n\n이외에도 가비지 컬렉터의 종류나 현재 회수 중인 메모리 영역에 따라 다른 객체들도 `임시로` 추가가 가능합니다.\n\n### 세대 단위 컬렉션 이론\n현재 상용 가상 머신들이 채택한 가비지 컬렉터들은 대부분 세대 단위 컬렉션 이론에 기초해 설계되었습니다.\n\n<span style=\"color:orange\">1. 약한 세대 가설 : 대다수 객체는 일찍 죽는다.</span>\n\n<span style=\"color:orange\">2. 강한 세대 가설 : 가비지 컬렉션 과정에서 살아남은 횟수가 늘어날수록 더 오래 살 가능성이 커진다.</span>\n\n> 💬 “늙었다는 것은 살아남았다는 것”\n\n이 두 가지 가정이 합쳐져 가비지 컬렉터들에 일관된 설계 원칙을 제공합니다.\n여기서 `나이 = 가비지 컬렉션에서 살아남은 횟수`이고, **대부분의 객체가 곧바로 죽을 운명이라면?** 살아남는 소수의 객체를 유지하는 방법에 집중하는 편이 유리합니다.\n한 번 살아남은 객체는 통계적으로 잘 죽지 않으니 다른 영역에 따로 모아 두고, 가상 머신이 그 영역을 회수하는 빈도를 줄이는 방식입니다.\n\n이러한 세대 단위 컬렉션 이론을 가상 머신에 적용한 설계자들은 **자바 힙**을 최소 두개의 영역으로 나누게 되었습니다.\n\n1. 신세대 : 가비지 컬렉션 때마다 다수의 객체가 죽고 살아남은 소수만 구세대로 승격\n2. 구세대 \n\n그러나 복잡해 보이는 상황이 하나가 있습니다. 🤔\n\n- 객체들은 단독으로 존재 X\n- 다른 세대에 존재하는 객체들을 참조하는 상황이 있음\n\n또한, 신세대에서만 가비지 컬렉션을 하고 싶어도 구세대에서 참조 중인 객체도 분명 있을 것입니다. 살아남을 객체를 찾으려면 고정된 `GC 루트`들뿐 아니라 `구세대 객체까지` 모두 탐색해야 하며, 이 경우 성능 면에서 확실히 부담이 큽니다. 이 문제를 풀기 위해 `세대 단위 컬렉션 이론`에 **3번째** 가정이 추가됩니다.\n\n<span style=\"color:orange\">3. 세대 간 참조 가설 : 세대 간 참조의 개수는 같은 세대 안에서의 참조보다 훨씬 적다.</span>\n\n상호 참조 관계의 두 객체는 `삶과 죽음을 함께하는 경향`이 있습니다. 신세대 객체가 세대 간 참조를 가지고 있을 때 구세대 객체는 잘 죽지 않기 때문에 가비지 컬렉션을 거쳐도 신세대 객체는 세대 간 참조 덕에 구세대로 승격됩니다. 이렇게 같은 세대가 되었으므로 세대 간 참조는 자연스럽게 사라게 됩니다.\n\n따라서 이 가설에 따르면 세대 간 참조의 수는 아주 적기 때문에 구세대 전체를 훑는 건 시간 낭비라고 판단합니다.\n\n\n### 마크-스윕 알고리즘\n![](mark-sweep-algorithm.png)\n가장 기본적인 가비지 컬렉션 알고리즘입니다. 먼저 회수할 객체들에 모두 표시(mark)한 다음, 표시된 객체들을 쓸어 담는(sweep) 방식입니다. 반대로, 살릴 객체에 표시(mark)하고, 표시되지 않은 객체를 회수(sweep) 하기도 합니다.\n\n#### 단점은?\n- 실행 효율이 일정하지 않음 : 자바 힙이 다량의 객체로 가득 차 있고 대부분이 회수 대상이라면? 표시하는 일 & 회수하는 일 모두 커짐 → 객체가 많아질수록 표시하고 쓸어 담는 작업의 효율이 떨어짐\n\n- 메모리 파편화가 심함 : 가비지 컬렉터가 쓸고 간 자리에는 불연속적인 메모리 파편이 만들어짐. → 파편화가 너무 심하면 프로그램이 큰 객체를 만들려 할 때 충분한 크기의 연속된 메모리를 찾기가 점점 어려워짐 → 또 다른 가비지 컬렉션 유발\n\n### 마크-카피 알고리즘\n![](mark-copy-algorithm.png)\n회수할 객체가 많아질수록 효율이 떨어지는 마크-스윕 알고리즘의 문제를 해결하기 위해 생겨나게 되었습니다. 가용 메모리를 똑같은 크기의 두 블록으로 나눠서 한 번에 한 블록만 사용하고, 한쪽 블록이 꽉 차면 살아남은 객체들만 다른 블록에 복사하고 기존 블록 목록을 한 번에 청소하는 방식입니다.\n\n만약 대다수 객체가 살아남으면? 메모리 복사에 상당한 시간 허비를 하게 됩니다.\n대다수 객체가 회수된다면? 생존한 소수의 객체만 복사하면 됨 & 복사 과정에서 객체들이 메모리 한쪽 끝에서 차곡차곡 쌓이기 때문에 메모리 파편화 문제로부터 해방됩니다.\n\n### 단점은?\n가용 메모리를 절반으로 줄여 낭비가 제법 심하다는 점\n\n오늘날 상용 자바 가상 머신은 대부분 신세대에 이 알고리즘을 적용합니다.\nIBM의 연구에 따르면 신세대 객체 중 `98`%가 첫 번째 가비지 컬렉션에 살아남지 못했고, 이는 신세대용 메모리 영역을 1:1로 나눌 필요가 없다는 결론이 나게 됩니다.\n\n![](young-gen-and-old-gen.png)\n신세대를 하나의 큰 에덴 공간(80%)과 두 개의 작은 생존자 공간(10%)으로 나누는데, 핫스팟 가상 머신에서 에덴과 생존자 공간의 비율은 기본적으로 8:1 (에덴 80% + 생존자 공간 중 하나 10%) 입니다. (낭비하는 공간은 단 10%뿐)\n\n- 98%의 객체가 회수된다는 데이터 = ‘일반적인 상황'에서 측정된 결과\n> 😮 10% 넘는 객체가 살아남는 특이 케이스는 어쩌고? \n\n이런 케이스에 대처하기 위한 설계로 `메모리 할당 보증 메커니즘` 개념이 등장합니다.\n\n### 메모리 할당 보증 메커니즘\n마이너 GC(신세대 GC)에서 살아남은 객체를 생존자 공간이 다 수용하지 못할 경우 다른 메모리 영역(구세대)를 활용해 메모리 할당을 보증하는 것으로, 이러한 할당 보증 메커니즘을 통해 가비지 컬렉션에서 살아남은 객체를 구세대에 바로 추가합니다.\n\n### 마크-컴팩트 알고리즘\n`마크-카피 알고리즘`은 객체 생존율이 높을수록 복사할 게 많아져서 효율이 나빠집니다. 공간을 50%나 낭비하기 싫다면 할당 보증용 공간을 따로 마련하여 대다수 객체가 살아남는 극단적 상황에 대처해야 하기 때문에 구세대에는 적합하지 않습니다. (객체 생존율이 높기 때문)\n\n![](mark-compact-algorithm.png)\n이는 마크-컴팩트 알고리즘인데, 표시 단계는 `마크-스윕`과 같습니다. 회수 대상 객체들을 모두 쓸어 담는 대신 생존한 모든 객체를 메모리 영역의 한쪽 끝으로 모은 다음, 나머지 공간을 한꺼번에 비웁니다. \n\n#### 마크-스윕 알고리즘과의 차이는?\n> 💬 메모리 이동이 일어난다는 점\n\n그런데? 가비지 컬렉션 후 살아남은 객체를 이동할지는 양날의 검과 같은 결정입니다. 구세대에서는 회수 때마다 살아남는 객체가 상당히 많을텐데, 생존한 객체들을 이동시킨 후, 이동된 객체들을 가리키던 기존 참조를 모두 갱신하는 것은 매우 부담되고, 그렇다고 `마크-스윕 알고리즘`처럼 살아있는 객체를 전혀 이동시키지 않는다면 힙이 파편화되는 문제가 발생합니다. 그러나 이러한 문제는 \n<span style=\"color:yellowgreen\">파편화 없는 할당 연결 리스트로 해결 가능</span>합니다.\n\n하드디스크나 SSD에는 물리적으로 연속된 공간이 없더라도 큰 파일을 저장할 수 있는 이유가 파일을 조각으로 나눠 물리적으로 떨어진 파티션에 저장한 다음 이를 파티션 테이블로 관리하기 때문입니다.\n\n대부분의 경우 메모리 파편화를 감내하면서 `마크-스윕`을 사용하다가, 객체 할당에 영향을 줄 만큼 파편화가 심해지면 `마크-컴팩트`를 돌려 연속된 공간을 확보하는 해법도 있습니다.\n\n### 회고 및 마무리\n\n책의 내용이 방대하였기에, 회사 동료분들과 함께 각 챕터별로 담당자를 맡아서 핵심 개념을 요약하여 공유하는 방식을 통해 효율적으로 스터디할 수 있었던 것 같습니다. 또한 `JVM`을 공부하면 공부할수록 이 분야는 논문을 준비하는 대학원 석사 연구생들이 연구해봐도 좋을 것 같다라고 느낄정도로 심오하고도 깊은 내용이 많았습니다. 안드로이드 개발을 하다보면, 필요에 따라 빌드 구성 시 `JVM` 옵션을 설정할 때도 있는데, 이와 관련해서도 그동안 몰랐던 옵션들도 새롭게 알게 되었습니다. 업무를 하면서 `JVM, GC`와 관련하여 더 공부해보고 싶을 때, 이 책을 자주 찾을 것 같습니다."}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}